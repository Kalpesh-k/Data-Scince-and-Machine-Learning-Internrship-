{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7fd888c",
   "metadata": {},
   "source": [
    "# ProgramMini Project 3–Twitter Sentimental Analysis Using NLP and Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffc0b63",
   "metadata": {},
   "source": [
    "# Dataset description:The data contain information about manyTweets in the form oftext and their types,as mentionedbelow.Tweets: Data is in the form ofa sentence written by individuals.category:  Numeric(0: Neutral, -1: Negative, 1: Positive)(It is our dependent variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18a2fd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ebbc974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from excel file\n",
    "df= pd.read_csv('C:/Users/Kalpesh__K__/Datasets/Twitter_Data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0d6facb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised “minimum government maximum...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kiya tho refresh maarkefir comment karo</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>surat women perform yagna seeks divine grace f...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>this comes from cabinet which has scholars lik...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>with upcoming election india saga going import...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gandhi was gay does modi</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  category\n",
       "0  when modi promised “minimum government maximum...      -1.0\n",
       "1  talk all the nonsense and continue all the dra...       0.0\n",
       "2  what did just say vote for modi  welcome bjp t...       1.0\n",
       "3  asking his supporters prefix chowkidar their n...       1.0\n",
       "4  answer who among these the most powerful world...       1.0\n",
       "5           kiya tho refresh maarkefir comment karo        0.0\n",
       "6  surat women perform yagna seeks divine grace f...       0.0\n",
       "7  this comes from cabinet which has scholars lik...       0.0\n",
       "8  with upcoming election india saga going import...       1.0\n",
       "9                         gandhi was gay does modi         1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79033ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of                                                clean_text  category\n",
       "0       when modi promised “minimum government maximum...  Negative\n",
       "1       talk all the nonsense and continue all the dra...   Neutral\n",
       "2       what did just say vote for modi  welcome bjp t...  Positive\n",
       "3       asking his supporters prefix chowkidar their n...  Positive\n",
       "4       answer who among these the most powerful world...  Positive\n",
       "...                                                   ...       ...\n",
       "162975  why these 456 crores paid neerav modi not reco...  Negative\n",
       "162976  dear rss terrorist payal gawar what about modi...  Negative\n",
       "162977  did you cover her interaction forum where she ...   Neutral\n",
       "162978  there big project came into india modi dream p...   Neutral\n",
       "162979  have you ever listen about like gurukul where ...  Positive\n",
       "\n",
       "[162980 rows x 2 columns]>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71e0e44e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised “minimum government maximum...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162975</th>\n",
       "      <td>why these 456 crores paid neerav modi not reco...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162976</th>\n",
       "      <td>dear rss terrorist payal gawar what about modi...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162977</th>\n",
       "      <td>did you cover her interaction forum where she ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162978</th>\n",
       "      <td>there big project came into india modi dream p...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162979</th>\n",
       "      <td>have you ever listen about like gurukul where ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162980 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               clean_text  category\n",
       "0       when modi promised “minimum government maximum...  Negative\n",
       "1       talk all the nonsense and continue all the dra...   Neutral\n",
       "2       what did just say vote for modi  welcome bjp t...  Positive\n",
       "3       asking his supporters prefix chowkidar their n...  Positive\n",
       "4       answer who among these the most powerful world...  Positive\n",
       "...                                                   ...       ...\n",
       "162975  why these 456 crores paid neerav modi not reco...  Negative\n",
       "162976  dear rss terrorist payal gawar what about modi...  Negative\n",
       "162977  did you cover her interaction forum where she ...   Neutral\n",
       "162978  there big project came into india modi dream p...   Neutral\n",
       "162979  have you ever listen about like gurukul where ...  Positive\n",
       "\n",
       "[162980 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75ccdd27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['clean_text', 'category'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d007ba7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the category column to categorical values\n",
    "df['category'] = df['category'].map({0: 'Neutral', -1: 'Negative', 1: 'Positive'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9bed483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_text    4\n",
      "category      7\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Drop null/missing values\n",
    "df = df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71667faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\kalpesh__k__\\anaconda3\\lib\\site-packages (3.7)\n",
      "Collecting nltk\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: joblib in c:\\users\\kalpesh__k__\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: click in c:\\users\\kalpesh__k__\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\kalpesh__k__\\anaconda3\\lib\\site-packages (from nltk) (2022.3.15)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kalpesh__k__\\anaconda3\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kalpesh__k__\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "Installing collected packages: nltk\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.7\n",
      "    Uninstalling nltk-3.7:\n",
      "      Successfully uninstalled nltk-3.7\n",
      "Successfully installed nltk-3.8.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93757000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# Define a function to clean text\n",
    "def clean_text(text):\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Convert to lower case\n",
    "    text = text.lower()\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "# Apply the clean_text function to the clean_text column\n",
    "df['clean_text'] = df['clean_text'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93540458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column with the length of each sentence\n",
    "df['length'] = df['clean_text'].apply(lambda x: len(x.split()))\n",
    "---------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3cddb86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['clean_text', 'category'], dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "42758f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\kalpesh__k__\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: click in c:\\users\\kalpesh__k__\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\kalpesh__k__\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kalpesh__k__\\anaconda3\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\kalpesh__k__\\anaconda3\\lib\\site-packages (from nltk) (2022.3.15)\n",
      "Requirement already satisfied: colorama in c:\\users\\kalpesh__k__\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaf5603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column with the length of each sentence\n",
    "df['length'] = df['clean_text'].apply(lambda x: len(x.split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e1a320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into dependent and independent variables\n",
    "X = df['clean_text'].values\n",
    "y = df['category'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bc18b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X)\n",
    "X = tokenizer.texts_to_sequences(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71172dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the sequences\n",
    "X = pad_sequences(X, padding='pre')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9a04df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input length and vocabulary size\n",
    "input_length = X.shape[1]\n",
    "vocab_size = len(tokenizer.word_index) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79deda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert the categorical labels to dummy variables\n",
    "y = pd.get_dummies(y).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d752a08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee59aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, 64, input_length=input_length),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.LSTM(128),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a2ce4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a3b197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3842d153",
   "metadata": {},
   "source": [
    "# Thank You "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eefad71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('twitter_data.csv', usecols=['clean_text', 'category'])\n",
    "\n",
    "# One-hot encode the sentences\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['clean_text'])\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "encoded_docs = tokenizer.texts_to_matrix(df['clean_text'], mode='binary')\n",
    "\n",
    "# Pad the sequences from the front side\n",
    "max_length = max([len(s.split()) for s in df['clean_text']])\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='pre')\n",
    "\n",
    "# Create dummy variables for the dependent variable\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(df['category'])\n",
    "y = encoder.transform(df['category'])\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_docs, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100, input_length=max_length))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = [1 if i>=0.5 else 0 for i in y_pred]\n",
    "\n",
    "# Measure performance metrics and accuracy\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608e7a71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3c7ed9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29db9000",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
